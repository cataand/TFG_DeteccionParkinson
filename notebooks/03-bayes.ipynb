{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import logging\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from paddel.preprocessing import get_data\n",
    "\n",
    "misc_df, classic_df, fresh_df, y = get_data(Path(\"../data/raw\"), Path(\"../data/cache\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = {\n",
    "    \"basic\": {\n",
    "        \"data\": misc_df,\n",
    "        \"params\": {},\n",
    "    },\n",
    "    \"classic\": {\n",
    "        \"data\": pd.concat([misc_df, classic_df], axis=1),\n",
    "        \"params\": {},\n",
    "    },\n",
    "    \"fresh\": {\n",
    "        \"data\": pd.concat([misc_df, fresh_df], axis=1),\n",
    "        \"params\": {\n",
    "            \"n_features\": [10, 20, 40, 80, 160, 240, 320, 400, 480, 560, 640, 720],\n",
    "        },\n",
    "    },\n",
    "    \"full\": {\n",
    "        \"data\": pd.concat([misc_df, classic_df, fresh_df], axis=1),\n",
    "        \"params\": {\n",
    "            \"n_features\": [10, 20, 40, 80, 160, 240, 320, 400, 480, 560, 640, 720],\n",
    "        },\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "models = {\n",
    "    \"SVC\": SVC,\n",
    "    \"KNeighborsClassifier\": KNeighborsClassifier,\n",
    "    \"RandomForestClassifier\": RandomForestClassifier,\n",
    "#    \"MLPClassifier\": MLPClassifier,\n",
    "#    \"AdaBoostClassifier\": AdaBoostClassifier,\n",
    "#    \"XGBClassifier\": XGBClassifier,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {\n",
    "    \"SVC\": {\n",
    "        'C': (1e-6, 1e+6, 'log-uniform'),\n",
    "        'gamma': (1e-6, 1e+1, 'log-uniform'),\n",
    "        'degree': (1, 8),\n",
    "        'kernel': ['linear', 'poly', 'rbf', 'sigmoid'],\n",
    "    },\n",
    "    \"KNeighborsClassifier\": {\n",
    "        'n_neighbors': (1, 31),\n",
    "        'metric': [\n",
    "            \"cityblock\",\n",
    "            \"cosine\",\n",
    "            \"l1\",\n",
    "            \"l2\",\n",
    "            \"nan_euclidean\"\n",
    "        ],\n",
    "    },\n",
    "    \"RandomForestClassifier\": {\n",
    "        'n_estimators': (5, 10000),\n",
    "        \"criterion\": [\"gini\", \"entropy\", \"log_loss\"],\n",
    "        \"max_features\": [\"sqrt\", \"log2\", None],\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skopt import BayesSearchCV\n",
    "from paddel import settings\n",
    "from sklearn.metrics import make_scorer, f1_score\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from paddel.preprocessing.transformer import FeatureSelector\n",
    "from sklearn.preprocessing import QuantileTransformer\n",
    "\n",
    "all_results = []\n",
    "\n",
    "for dataset_name, dataset in datasets.items():\n",
    "    data = dataset[\"data\"]\n",
    "    dataset_params = dataset[\"params\"]\n",
    "    data = QuantileTransformer(n_quantiles=20).set_output(transform=\"pandas\").fit_transform(data)\n",
    "\n",
    "    if \"n_features\" in dataset_params:\n",
    "        n_features_list = dataset_params[\"n_features\"]\n",
    "    else:\n",
    "        n_features_list = [0]\n",
    "\n",
    "    for model_name, model in models.items():\n",
    "        search_spaces = parameters[model_name]\n",
    "\n",
    "        grid = BayesSearchCV(\n",
    "            estimator=model(),\n",
    "            search_spaces=search_spaces,\n",
    "            n_iter=1000,\n",
    "            cv=RepeatedKFold(n_splits=2, n_repeats=5),\n",
    "            n_jobs=settings.max_processes,\n",
    "            verbose=10,\n",
    "            scoring=make_scorer(f1_score),\n",
    "        )\n",
    "\n",
    "        for n_features in n_features_list:\n",
    "            selected_data = FeatureSelector(n_features=n_features).fit_transform(data, y)\n",
    "\n",
    "            print(f\"Doing dataset: {dataset_name}, model: {model_name}, features: {selected_data.shape[1]}\")\n",
    "\n",
    "            grid.fit(selected_data, y)\n",
    "            results = pd.DataFrame(grid.cv_results_)\n",
    "\n",
    "            results.insert(0, 'n_features', n_features)\n",
    "            results.insert(0, 'dataset', dataset_name)\n",
    "            results.insert(0, 'model', model_name)\n",
    "\n",
    "            all_results.append(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_results = pd.concat(all_results, ignore_index=True)\n",
    "all_results.to_csv(\"../data/results/bayes_results.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
