\capitulo{Conceptos teóricos}
\label{cha:Conceptos teóricos}

Este capítulo define algunos de los conceptos teóricos que se mencionan en este
documento.

\section{Minería de Datos}

La minería de datos es un área de la inteligencia artificial que consiste en el
diseño de algoritmos y modelos que permitan a los ordenadores aprender la regla
general que define un conjunto de datos sin ser explícitamente programados para
ello.

La minería de datos incluye, además de algoritmos de aprendizaje, todas las
metodologías y técnicas utilizadas para el tratamiento y filtrado del conjunto
de datos disponible.

\subsection{Preprocesado}

La información con la que se entrene un modelo de aprendizaje automático
determina en gran medida el rendimiento que podrá alcanzar, debido a esto es muy
frecuente realizar un paso previo a la creación del modelo, denominado
\textit{preprocesado} \cite{enwiki:1138293751}.

El objetivo del preprocesado es transformar la entrada de datos iniciales con el
fin de permitir y facilitar que un modelo se adapte a los mismos.

El preprocesado también tiene una gran influencia sobre el tiempo de computación
necesario para entrenar un modelo y sobre la complejidad que necesitará para
adaptarse a los datos.

El preprocesado suele componerse de algunos de los siguientes pasos.

\subsubsection{Extracción de características}

La extracción de características es el proceso de identificar, seleccionar y
transformar atributos relevantes de los datos de entrada para su uso en un
modelo. Por ejemplo, en este proyecto, se han extraido características como la
velocidad o amplitud de movimiento a partir de un vídeo.

Existen diversas técnicas para la extracción de características, incluyendo las
selección manual de características, o técnicas automatizadas como la reducción
de dimensionalidad, la extracción de características basada en redes neuronales
~\cite{intrator1991feature}, entre otras. La elección de la técnica de extracción
de características depende del conjunto de datos, del problema específico de
aprendizaje automático que se está abordando y del tipo de modelo de aprendizaje
automático que se está utilizando.

\subsubsection{Selección de características}

Los datos de entrada pueden ser muy complejos y estar compuestos por una gran
cantidad de información redundante o no relevante para el modelo. La selección
de características se utiliza para identificar  las características más
relevantes y representativas de los datos, que pueden ser utilizadas para
entrenar modelos de aprendizaje automático con mayor eficacia.

En la selección de características, se pueden utilizar técnicas como el análisis
de componentes principales (PCA)~\cite{mackiewicz1993principal}, el análisis
discriminante lineal (LDA)~\cite{xanthopoulos2013linear} o pruebas de
significancia, entre otras.

\subsubsection{Normalización}

Existen modelos muy sensibles a que existan diferencias en la escala de los
distintos atributos, como, por ejemplo, \textit{k-nearest neighbors}, por lo que
es muy habitual que en la fase de preprocesado se realize una normalización de
los datos, es decir, transformarlos de tal forma que utilicen la misma escala,
en general se suelen tomar valores en los intervalos $[0, 1]$ o $[-1, 1]$.

Aunque lo más habitual es que la normalización se haga sin distorsionar las
diferencias existentes entre los valores previos, existen situaciones en las que
puede ser ventajoso utilizar un método de normalización que sí altere estas
diferencias, por ejemplo, la normalización por cuantiles
~\cite{enwiki:1138433182}, en la que se modifican los valores para que sigan una
distribución normal, lo que consigue que, si existen valores muy lejanos a los
valores más comunes (\textit{outliers}), estos se acerquen al resto. 

\subsection{Aprendizaje supervisado}

Dentro del aprendizaje automático existen tres ramas o variantes dependiendo del
conjunto de datos del que se disponga, ya que estos datos son los que determinan
las técnicas, algoritmos y metodologías que se podrán utilizar, estas variantes
son el aprendizaje no supervisado, en el que los datos no están etiquetados, es
decir, el atributo que se desea predecir es desconocido (el ejemplo más
característico es el \textit{clustering}), aprendizaje semisupervisado, en el
que solo una parte de los datos están etiquetados, y el aprendizaje supervisado,
en el que el conjunto de datos está completamente etiquetado, este último es el
tipo de aprendizaje utilizado realizado en el proyecto y del que trata este
apartado.

El enfoque del aprendizaje supervisado consiste en la utilización de dos
conjuntos de datos, uno de entrenamiento (con datos etiquetados) y otro de test
(con datos no etiquetados), a continuación se utiliza un algoritmo de
aprendizaje para crear un modelo que <<aprenda>> de las instancias del conjunto
de entrenamiento una regla o procedimiento que le permita identificar los datos
del conjunto de test con la mayor precisión posible
\cite{learned2014introduction}.


\subsection{Clasificación}

En el ámbito del aprendizaje supervisado, clasificar instancias en categorías
predeterminadas es uno de los principales problemas a resolver.

En general, la resolución de un problema de clasificación se caracteriza por
delimitar qué zonas del espacio que contiene todas las instancias posibles
pertenecen a cada categoría, es decir, definir fronteras a partir de las cuales
las instancias pasan de una categoría a otra.

Existe una gran cantidad de métodos y algoritmos de clasificación que se pueden
utilizar para determinar estas fronteras, dependiendo del problema específico
que se intente resolver unos algoritmos se comportarán mejor que otros.

% TODO: Algunos ejemplos de algoritmos con alguna gráfica de clasificación con 2
% características.

\subsection{Sobreajuste}

Normalmente solo se dispone de una pequeña muestra para entrenar un modelo que
encuentre la regla general que define la población y se adapte lo mejor posible
a esta.

El problema de esto es que, si se utilizan todos los datos disponibles durante
el entrenamiento, no existe ninguna forma para verificar el comportamiento del
modelo cuando se encuentre con instancias que no ha visto antes. Esto hace
posible que el modelo ``memorice'' los datos con los que se ha entrenado pero no
generalice bien al encontrarse con datos nuevos. Esto se conoce como
sobreajuste.

% TODO: Añadir alguna gráfica.

Una solución muy común al sobreajuste es separar los datos disponibles en dos
grupos, un conjunto de entrenamiento y un conjunto de test o prueba. Durante el
entrenamiento el modelo solo tendrá acceso al conjunto de datos de
entrenamiento, mientras que el conjunto de test es utilizado para determinar el
rendimiento del modelo sobre datos nuevos mediante una de las métricas de
evaluación que se verán a continuación.

\subsection{Evaluación del modelo}

Para determinar si un modelo es mejor que otro es necesario definir alguna
métrica que asigne un valor numérico al rendimiento de cada modelo.

La métrica más intuitiva es lo que se conoce como precisión (\textit{accuracy}),
que es simplemente la proporción de predicciones (clasificaciones) acertadas del
total de predicciones realizadas.

Al igual que ocurren con el algoritmo de clasificación empleado, la métrica que
se use debe ser seleccionada en función del problema en cuestión. Una situación
muy común en la que utilizar la precisión no es lo más ideal es cuando se
trabaja con conjuntos de datos desbalanceados, es decir, cuando existen más
instancias de una clase que de otra.

Lo anterior es muy común en el ámbito médico cuando se intenta crear un modelo
que determine si un paciente padece una enfermedad concreta o no. En estas
situaciones se suele tener un grupo de control muy grande que no padece la
enfermedad y un grupo relativamente pequeño que sí la padece. Si, por ejemplo,
las proporciones de clases son 95\% y 5\% respectivamente, un modelo que siempre
prediga que el paciente no padece la enfermedad en cuestión obtendrá una
precisión del 95\%, lo que podría dar la falsa impresión de que se ajusta bien a
los datos, cuando, en realidad, es un modelo completamente inútil.

Algunas alternativas a la precisión incluyen:

\begin{itemize}
    \item \textbf{Sensibilidad}: Para una clase concreta, indica la capacidad
    del modelo de clasificar correctamente instancias de esa clase. En el caso
    médico esta métrica podría ser interesante para encontrar aquellos pacientes
    que sí padecen la enfermedad, aunque se clasifiquen mal algunos que no la
    padecen.
    \item \textbf{Especificidad}: Para una clase concreta, indica la capacidad
    del modelo para clasificar correctamente instancias que no pertenecen esa
    clase.
    \item \textbf{Valor-F1}: Es una medida que combina la sensibilidad y la
    especificidad mediante una media armónica.
\end{itemize}

\subsection{Fuga de información}

En el campo del aprendizaje automático las fugas de información se producen
cuando, de alguna forma, se utiliza información perteneciente al conjunto de
datos de test para entrenar un modelo, esto no significa únicamente utilizar
instancias de test durante el entrenamiento, las fugas de información se pueden
producir de forma mucho más sutil y ser difíciles de detectar. Por ejemplo, si
se utilizase el conjunto de test para seleccionar las características durante el
preprocesado se estaría produciendo una fuga de información.

Las fugas de información no son algo que debería ser siempre evitado, existen
situaciones en las que son necesarias dependiendo del caso concreto. Pero sí es
importante que sean detectadas y tenidas en cuenta a la hora de analizar los
resultados obtenidos, ya que, en caso contrario, se podría llegar a conclusiones
equívocas (demasiado optimistas por ejemplo).

\subsection{Validación cruzada}

En un apartado anterior se ha visto que para evitar el sobreajuste se puede
dividir la muestra de datos disponible en un conjunto de datos de entrenamiento
y uno de test. Al realizar esta división es posible que, en especial al trabajar
con muestras pequeñas, se realice una división que no sea útil para validar el
modelo. Por ejemplo, si por casualidad se seleccionase un conjunto de test
``fácil de predecir'' con el conjunto de entrenamiento dado, se medirá un
rendimiento mayor al real.

La solución a esto es la validación cruzada, que consiste en utilizar múltiples
pares de conjuntos de validación y test, de tal forma que se entrenen y validen
tantos modelos como cantidad de estos pares y cada instancia sea utilizada para
la validación al menos una vez, el resultado final de la validación es la media
de la métrica elegida de cada iteración.

Existen varios métodos para determinar el número de iteraciones a realizar y el
tamaño de los grupos de entrenamiento y test en cada iteración, por ejemplo:

\begin{itemize}
    \item \textbf{\textit{Leave-One-Out}}: Para una muestra de tamaño $N$,
    consiste en realizar $N$ iteraciones de entrenamiento y validación
    utilizando cada vez una única instancia para el conjunto de test. Es un
    método que se acerca bastante al rendimiento que se obtendría si se
    utilizase la muestra entera como conjunto de entrenamiento, pero tiene el
    problema de que se van a tener que realizar $N$ iteraciones, lo que implica
    un tiempo de computación necesario muy grande.
    \item \textbf{\textit{K-fold}}: Consite en dividir la muestra en conjuntos
    de entrenamiento y test de proporciones $(K-1)/K$ y $1/K$ respectivamente,
    realizando un total de $K$ iteraciones. Además se puede realizar varias
    repeticiones de este tipo de validación cruzada para reducir la variabilidad
    del error obtenido.
\end{itemize}

\subsection{Optimización de hiperparámetros}

Los algoritmos de clasificación suelen tener parámetros que determinan la forma
en la que se van a ajustar a los datos, por ejemplo, la tasa de aprendizaje o el
número de iteraciones máximas, estos valores se denominan hiperparámetros.

El proceso de búsqueda dentro del espacio que contiene todas las combinaciones
posibles de hiperparámetros para un algoritmo concreto se denomina optimización
de hiperparámetros.

En general, la optimización de hiperparámetros consiste en probar diferentes
combinaciones de valores y realizar el proceso de entrenamiento y test mediante
validación cruzada con una métrica apropiado hasta dar con la combinación más
adecuada. Existen varias formas para realizar esto, como, por ejemplo:

\begin{itemize}
    \item \textbf{\textit{Grid search}}: Proceso mediante el cual se definen los
    valores posibles que puede tomar cada parámetro y se prueba cada combinación
    de estos valores hasta encontral la mejor. Es una búsqueda exhaustiva que
    puede dar lugar a una gran cantidad de combinaciones, lo que implica un
    tiempo de computación muy grande.
    \item \textbf{\textit{Randomized search}}: Proceso similar al anterior en el
    que se especifican los valores posibles para cada parámetro, pero en este
    caso se realiza la búsqueda de forma aleatoria de forma que se limita el
    tiempo de computación necesario. Se puede utilizar para obtener una vista
    general del espacio de combinaciones de parámetros para realizar
    posteriormente una búsqueda más exhaustiva en un subespacio más pequeño.
    \item \textbf{\textit{Técnicas de optimización}}: Existen diversos métodos
    que intentan determinar la forma que tiene el rendimiento del modelo con
    respecto al espacio de combinaciones de parámetros posibles utilizando
    iteraciones anteriores para buscar los valores óptimos sin tener que probar
    todas las combinaciones como ocurre con \textit{grid search}. Un ejemplo de
    esto es la Optimización Bayesiana \cite{wu2019hyperparameter} en la que se
    intenta predecir la forma que toma la métrica de evaluación en función de
    los hiperparámetros elegidos, y así realizar una búsqueda más efectiva.
\end{itemize}
