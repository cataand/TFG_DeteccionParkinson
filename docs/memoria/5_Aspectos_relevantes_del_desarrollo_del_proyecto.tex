\capitulo{Aspectos relevantes del desarrollo del proyecto}
\label{cha:Aspectos relevantes del desarrollo del proyecto}

Este apartado contiene algunos aspectos relevantes sobre el desarrollo del
proyecto, incluyendo las razones detrás de las decisiones tomadas durante este y
el impacto que dichas decisiones han tenido sobre los resultados obtenidos.

\section{Fase de experimentación}

El conjunto de datos disponible durante la fase de experimentación consiste en
158 muestras con los siguientes <<atributos>>:

\begin{itemize}
    \item Si la persona correspondiente a la instancia padece la enfermedad de
    Parkinson. Es lo que se busca predecir.
    \item Archivo de vídeo de una mano de la persona realizando la prueba de
    <<finger-tapping>>.
    \item Mano que aparece en el vídeo (izquierda o derecha).
    \item Fecha en la que se ha tomado el vídeo (irrelevante).
    \item Edad de la persona.
    \item Sexo de la persona.
    \item Mano dominante de la persona.
\end{itemize}

Cabe destacar que se ha tomado una muestra de cada mano de cada persona. Por lo
que este conjunto de datos ha sido obtenido de 79 personas. Aun así, se ha
tomado cada mano como una instancia distinta con el objetivo de tener más
instancias con las que trabajar.

Además, se dispone de 69 instancias de personas que padecen la enfermedad de
Parkinson y 89 instancias de personas sanas, por lo que se está trabajando con
un conjunto de datos ligeramente desbalanceado. Esto deberá tenerse en cuenta
para que no influya en los resultados obtenidos, por ejemplo, seleccionando
métricas adecuadas.

\subsection{Procesado de vídeo}

El objetivo de la fase de experimentación es crear un sistema que tenga como
entrada los atributos antes mencionados (salvo el objetivo) y por salida si esos
atributos corresponden con una persona que padece la enfermedad de Parkinson
(posiblemente junto con el grado de confianza de la predicción).

Los algoritmos de aprendizaje automático típicamente están diseñados para
trabajar con atributos numéricos, por lo que los atributos disponibles deben ser
transformados durante el preprocesado. Esto se puede realizar en la mayoría de
los casos mediante simples métodos de minería de datos, como, por ejemplo, la
codificación de variables categóricas. Pero hay un problema, el archivo de
vídeo.

En este caso, una imagen es una matriz tridimensional de dimensiones
$(ancho \times alto \times 3)$, donde la tercera dimensión representa los valores
rojo, verde y azul del píxel correspondiente. Un vídeo es una secuencia de
imágenes junto con información adicional, es este caso solamente es relevante la
tasa de refresco, que es la frecuencia a la que ha sido capturada cada imagen.
Esto es de gran importancia para dar una componente temporal al vídeo.

Con lo anterior se puede ver que un vídeo no se puede utilizar de forma directa,
sino que deberá pasar por una fase multietapa de preprocesado para ser
transformado a un conjunto de valores numéricos que lo describen.

\subsubsection{Extracción de <<landmarks>>}

Una <<landmark>> en el campo de la visión artificial es un punto de referencia
que se corresponde con un objeto físico. El objetivo de esta fase es convertir
el vídeo de la prueba de <<finger-tapping>> a una secuencia o serie temporal de
conjuntos de <<landmarks>> los cuales representan la posición de las diferentes
partes de la mano durante cada instante concreto.

El primer paso para lograr esto es leer las imágenes del archivo de vídeo, esto
ha sido logrado mediante la librería de <<bindings>> de OpenCV para Python.
OpenCV es una librería de uso general para realizar tareas relacionadas con la
visión artificial, y permite leer multitud de formatos de vídeo mediante un
flujo de imágenes.

Se ha tomado especial precaución para no cargar en memoria todas las imágenes
del vídeo, sino ir leyéndolas cuando son necesarias. Un archivo de vídeo ocupa
relativamente poco espacio en disco debido a que está codificado mediante un
<<codec>> determinado, lo que reduce el tamaño del archivo. Pero, para poder
trabajar con las imágenes del vídeo, este debe ser decodificado.

La magnitud de lo anterior se ve claramente con el siguiente ejemplo. Un vídeo
con una resolución de 1920x1080 a 30 fotogramas por segundo codificado mediante
el códec H264 que ocupa 50,7MB, decodificado, ocuparía en torno a los 3,7GB.

A continuación, se deben extraer las <<landmarks>> de las imágenes leidas. Esto
ha sido logrado mediante la librería Mediapipe Hands \cite{zhang2020mediapipe},
que permite extraer los siguentes puntos a partir de una imagen:

\imagen{relevant_aspects/hand-landmarks.png}{Mediapipe Hands <<Landmarks>>}{1}

Debido a la perspectiva desde la que se han tomado los vídeos de la prueba de
<<finger-tapping>> hay algunas <<landmarks>> que quedan ocluídas en varias
ocasiones, lo que hace su posición detectada poco fiable. Consecuentemente, se
desechan las <<landmarks>> en el intervalo [9-17] para solo tomar en cuenta la
parte <<frontal>> de la mano.

Mediapipe Hands ofrece la posibilidad de extraer <<landmarks>> de las imágenes
como si estas no tuviesen relación entre sí o realizar la extracción teniendo en
cuenta que se trata de un vídeo, así considerando los resultados anteriores para
determinar de forma más precisa las <<landmarks>> del fotograma actual. Esto
tiene la gran desventaja de que hace imposible la paralelización de este proceso
(debido a que cada extracción depende de los resultados anteriores).

Lo anterior no tiene un gran efecto durante la fase de investigación, ya que sí
se puede paralelizar la extracción de <<landmarks>> de cada vídeo. Donde sí
tiene efecto es sobre la aplicación web, empeorando la experiencia de los
usuarios.

En última instancia se tomó la decisión de no usar paralelización, y así obtener
resultados más precisos. Una alternativa planteada fue realizar la extracción en
paralelo solamente en la aplicación, pero esto se descartó ya que esto podría
introducir inconsistencias y variables adicionales que podrían influir sobre el
rendimiento del modelo al ser usado desde la aplicación web.

\subsubsection{Extracción de series temporales}

Tras el proceso descrito en el apartado anterior se dispone una secuencia de
datos similar a la de la figura \ref{fig:relevant_aspects/poses_series.png}:

\imagen{relevant_aspects/poses_series.png}{Serie temporal de <<landmarks>>}{1}

Cada fila representa la pose de la mano durante un fotograma concreto. Se puede
observar que el índice es una fecha completa en lugar de otras opciones más
convenientes como los segundos desde el inicio del vídeo o lo que se conoce como
<<timestamp>>. Esto es una imposición de TSFresh para poder realizar la
extracción de características teniendo en cuenta esta componente temporal.

Cada celda representa el punto en el espacio en el que se encuentra la
<<landmark>> correspondiente en un instante de tiempo.

Aunque estas series temporales son una simplificación muy grande de lo vídeos
iniciales, aun no son del todo útiles. Al ser información sobre la posición en
el espacio, es dependiente de la forma en la que ha sido tomada la grabación. En
un entorno controlado esto no sería mucho problema, pero en este caso, como se
desea hacer el uso del sistema accesible a cualquier persona sin necesitar
equipamiento especial, se deben buscar alternativas.

En este caso se ha decidido tomar el ángulo entre la punta del dedo pulgar, la
muñeca y la punta del dedo índice, ya que el ángulo es una medida insensible a
la escala, por lo que no depende de cómo se ha tomado el vídeo ni del tamaño de
la mano de la persona. Quedando como resultado una serie temporal como en la
figura \ref{fig:relevant_aspects/angle_series.png}. La unidad usada en estos
ángulos es el radián.

\imagen{relevant_aspects/angle_series.png}{Serie temporal de ángulos}{0.5}

\subsubsection{Extracción de características}

El último paso para convertir un archivo de vídeo a atributos útiles para
entrenar un modelo de aprendizaje es extraer características que describan la
serie temporal obtenida. Algunos de estos atributos han sido extraídos de forma
específica teniendo en cuenta este problema concreto, mientras que otros (la
mayoría) son atributos genéricos para cualquier serie temporal.

\paragraph{Detección de toques y amplitudes}

Para varios atributos específicos al problema han sido utilizados los instantes
de tiempo en los que se producen toques (el pulgar y el índice tocan) y
amplitudes máximas en el movimiento de <<finger-tapping>>.

La detección de estos instantes ha sido realizada mediante una búsqueda de
máximos gracias a la función \texttt{find\_peaks} de la librería
\href{https://scipy.org/}{scipy}. Pero esta función por sí sola no da muy buenos
resultados.

\imagen{relevant_aspects/raw_peaks.png}{Máximos locales de la evolución de la amplitud a lo largo de un vídeo}{0.7}

El eje horizontal representa el tiempo que ha transcurrido desde el inicio del
vídeo. El eje vertical representa el ángulo en radianes entre el dedo índice, la
muñeca y el pulgar.

Se puede apreciar que obtener todos los máximos locales no es la mejor opción.
Debe incorporarse algún criterio para determinar si un máximo debería tenerse en
cuenta o no. La función \texttt{find\_peaks} tiene algunos parámetros para este
propósito.

Tras probar varias opciones y comprobar manualmente los resultados obtenidos
sobre diferentes vídeos, se determinó que la mejor opción es establecer la
prominencia mínima (parámetro \texttt{prominence} de \texttt{find\_peaks}) que
debe tener un máximo local para ser considerado.

La prominencia se define como la medida que determina cuánto destaca un máximo
con respecto a sus máximos más cercanos. Se probaron varios valores estáticos,
pero como cada vídeo tiene características diferentes era necesario utilizar
algo más dinámico. La desviación típica se comportaba bastante bien, pero cuando
la amplitud variaba con el tiempo (síntoma de la enfermedad de Parkinson) los
máximos de menor magnitud no eran detectados.

Lo anterior fue solucionado  mediante el uso de una desviación típica móvil. Se
establece una ventana que determina la <<zona>> a la que pertenece un valor y se
utiliza la desviación típica de esa <<zona>> como prominencia mínima para que el
punto pueda ser considerado un máximo.

\imagen{relevant_aspects/rolling_std_peaks.png}{Máximos mediante desviación típica móvil de la evolución de la amplitud a lo largo de un vídeo}{0.7}

Se puede apreciar que los resultados son apreciablemente mejores. Incluso cuando
la amplitud decrece con el tiempo:

\imagen{relevant_aspects/rolling_std_peaks_id.png}{Amplitudes mediante desviación típica móvil con la enfermedad de Parkinson}{0.7}

Aunque si el movimiento es errático, los resultados también lo son, como es de
esperar.

\imagen{relevant_aspects/rolling_std_peaks_erratic.png}{Amplitudes mediante desviación típica móvil con movimiento errático}{0.7}

Para detectar los toques (mínimos) es tan simple como utilizar la serie de
ángulos negada para detectar los puntos donde se encuentran los máximos. Además,
se ha establecido un umbral para que solo se consideren toques si se encuentra
entre 0 y 0,1 radianes.

\imagen{relevant_aspects/rolling_std_valleys.png}{Detección de toques mediante desviación típica móvil}{0.7}

\paragraph{Características detectadas}

A continuación se van a detallar algunas de las características extraídas de
mayor interés. Estos valores ya son atributos que describen el vídeo, por lo que
pueden ser utilizados para la generación de un modelo.

\begin{itemize}
    \item \textbf{Velocidad media del movimiento}: Una característica de la
    bradicinesia es la ralentización del movimiento. Esto va a ser reflejado en
    la velocidad media (en radianes por segundo) que tiene el movimiento
    \item \textbf{Frecuencia de amplitudes y toques}: Dos magnitudes que miden
    cuántos toques o amplitudes se realizan por segundo de media durante el
    movimiento.
    \item \textbf{Amplitud media}: Otra característica de la enfermedad de
    Parkinson es la debilidad, lo que se puede ver reflejado sobre la amplitud
    media del movimiento. Es simplemente la media de las amplitudes antes
    detectadas.
\end{itemize}

Además de las anteriores, se extrajeron 794 características genéricas
mediante la librería TSFresh.

\subsection{Limpieza de datos}

En este punto se dispone de un conjunto de 158 instancias y unos 800 atributos,
algunos de ellos categóricos, por lo que deberán ser codificados para que sean
atributos numéricos, con los que se trabaja mejor.

Además, se determinó que todas las instancias deberán tener un tiempo de
detección de la mano realizando la prueba de <<finger-tapping>> mínimo de 15
segundos para garantizar en cierto modo la precisión de los atributos extraídos
y poder comparar instancias con el mínimo número de influencias sobre las que no
se tiene control.

Debido a la decisión anterior se pasó de disponer de 158 instancias a únicamente
156. Esto es desafortunado debido al ya pequeño número de muestras, pero se
consideró una pérdida que merece la pena con el fin de obtener mejores
resultados.

Por último, se sustituyeron las característica <<mano dominante>> y <<mano que
aparece en el vídeo>> por una única característica <<es la mano que aparece en
el vídeo la dominante>> con el objetivo de reducir la conocida <<maldición de la
dimensionalidad>> al mismo tiempo que se mantiene la información relevante.

\subsection{Normalización}

Algunos algoritmos se ven muy afectados por la escala en la que se presentan los
atributos, uno de los casos más claros es <<\textit{k} vecinos más cercanos>>.

Debido a esto es importante normalizar los atributos. Se han probado varios
métodos y encontrado que la normalización por cuantiles funciona ligeramente
mejor que sus contrapartidas.

La normalización por cuantiles se caracteriza por hacer que los estadísticos de
cada atributo sean idénticos a los de una distribución concreta (en este caso
una distribución uniforme). Esto se consigue ignorando la magnitud de un
atributo y teniendo en cuenta únicamente su posición en la secuencia de todas
las instancias ordenadas según el atributo que se está normalizando.

Al no tener en cuenta la magnitud, la transformación anterior es de gran
utilidad para tratar lo que se conoce como <<outliers>>, que son instancias con
atributos que se alejan mucho de la regla.

\subsection{Búsqueda del mejor modelo}

En este punto se dispone de 4 conjuntos de datos sobre 156 instancias:

\begin{itemize}
    \item \textbf{Atributos iniciales}: Atributos de los que se disponía al
    inicio, como la edad o el sexo de la persona.
    \item \textbf{Atributos extraídos de vídeo propios}: Son los atributos cuya
    extracción ha sido descrita en los apartados anteriores, como la velocidad
    del movimiento o la frecuencia de toques.
    \item \textbf{Atributos extraídos de vídeo con TSFresh}: Son los 794
    atributos del vídeo extraídos mediante TSFresh.
    \item \textbf{Variable objetivo}: Si la instancia corresponde con una
    persona que padece la enfermedad de Parkinson. Es lo que se intenta predecir.
\end{itemize}

A priori es muy difícil o incluso imposible saber cómo van a comportarse
diferentes algoritmos al enfrentarse a distintos subconjuntos de la información
disponible. Por lo que la única opción es probar diferentes configuraciones con
la esperanza de encontrar una que se adapte considerablemente bien a los datos.
En este sentido el aprendizaje automático es más un arte que una ciencia exacta.

En este caso se ha realizado una búsqueda exhaustiva (o \textit{grid-search})
con las siguientes variables:

\begin{itemize}
    \item \textbf{Conjunto de datos}: El conjunto de datos utilizado para el
    entrenamiento ha sido cambiado de dos formas distintas:
    \begin{itemize}
        \item Distintas combinaciones de los conjuntos de datos anteriores.
        \item Selección de un distinto número de los atributos según su
        relevancia estimada mediante TSFresh.
    \end{itemize}
    \item \textbf{Algoritmo de aprendizaje}: Se han probado varios algoritmos de
    aprendizaje. (Máquinas de vectores de soporte, Naive Bayes, \textit{k}
    vecinos más cercanos, Perceptrón multicapa, AdaBoost, etc.)
    \item \textbf{Parámetros de los algoritmos}: Se ha variado la configuración
    de cada uno de los algoritmos anteriores. Este proceso se denomina
    optimización de hiperparámetros.
    
    Además, existen combinaciones de parámetros sin sentido, por ejemplo, variar
    el grado de la función para una máquina de vectores de soporte con
    <<kernel>> lineal. Esto se debe tener en cuenta para no aumentar el tiempo
    requerido de forma inútil.
\end{itemize}

Cabe destacar que la selección de características se realiza teniendo en cuenta
la totalidad del conjunto de datos, no solo el de entrenamiento. Esto produce
fugas de información durante la validación cruzada ya que las características
seleccionadas son la consideradas mejores tanto para el conjunto de
entrenamiento como el de test.

Una opción para solventar lo anterior es realizar la selección de
características en cada <<fold>> de la validación cruzada, usando únicamente el
conjunto de entrenamiento. Pero esta operación es muy costosa al trabajar con
cientos de atributos. Este cambio incrementa la duración de la búsqueda
<<grid-search>> en varios órdenes de magnitud. Se tomó la decisión de aceptar
las fugas de información ya que lo que se pretende es comparar el rendimiento de
distintos modelos, por lo que los resultados van a seguir siendo relevantes.

\subsubsection{Resultados}

Tras realizar la búsqueda se ha obtenido una tabla de dimensiones bastante
grandes (con una fila por cada combinación de variables probada) con los
resultados obtenidos.

En este apartado se exponen los resultados obtenidos además de algunos detalles
interesantes.

\paragraph{Número de características} Para la selección de características estas
son ordenadas mediante una tabla de relevancia creada por TSFresh en la que se
realiza una prueba de significancia (contraste de hipótesis) de cada atributo,
los p-valores resultantes son posteriormente evaluados para detectar falsos
positivos, dando resultado a la tabla de relevancia final.

En un principio se realizó la búsqueda variando el número de características
seleccionadas entre 1 y 120, obteniendo los resultados dependiendo esta cifra de
la figura \ref{fig:results/1.png} (cada punto corresponde con la configuración
de mayor precisión con ese número de características).

\imagen{results/1.png}{Resultados iniciales variando número de características}{0.7}

Se pensó que se había alcanzado la <<maldición de la dimensionalidad>>, por la
que utilizar más información para entrenar un modelo empeora la precisión, ya
que muchas de las nuevas características van a ser menos relevantes.

En este caso ocurrió al contrario, porque al ampliar el espacio de búsqueda para
utilizar más características se obtuvieron los resultados de la figura
\ref{fig:results/2.png}.

\imagen{results/2.png}{Resultados ampliando número de características probadas}{0.7}

Se observa que la precisión aumenta hasta las 320 características seleccionadas.
Esto puede resultar ilógico debido a que las características se seleccionan en
orden de relevancia. Se sospecha que esto es debido a la forma en la que tratan los
algoritmos algunas combinaciones de atributos que no eran posibles al realizar
una selección de menos características.

\paragraph{Comparación de algoritmos}

La figura \ref{fig:results/3.png} muestra la precisión de los algoritmos
probados en función del número de características seleccionadas.

\imagen{results/3.png}{Precisión de diversos algoritmos dependiendo del número de características}{0.7}

Se aprecia que la mejor precisión se obtiene con SVC (Máquina de Vectores de
Soporte) y 320 características seleccionadas, aunque Random Forest se queda
bastante cerca.

La figura \ref{fig:results/4.png} muestra la precisión del algoritmo SVM para
diferentes funciones <<kernel>> y número de características seleccionadas.

\imagen{results/4.png}{Precisión de SVM según el número de características y el <<kernel>> usado}{0.7}

A continuación, en la figura \ref{fig:results/5.png} se muestra la diferencia de
precisión entre distintos grados para SVM con <<kernel>> polinomial.

\imagen{results/5.png}{Precisión de SVM con <<kernel>> polinomial en función del grado}{0.7}

Se puede ver que se alcanza la precisión máxima con un <<kernel>> polinomial de
grado 8, seguido de los grados 5 y 7. 

Aunque utilizar grado 8 ha dado la precisión máxima, la diferencia con respecto
a utilizar grado 5 es despreciable, por lo que se ha tomado la decisión de
utilizar un modelo de grado 5 como modelo final para la aplicación web, con el
objetivo de seleccionar un modelo más <<simple>> y evitar en la medida de lo
posible que se produzca sobreajuste al realizar el entrenamiento con el conjunto
de datos completo.

\paragraph{Modelo final} Para generar el modelo final se ha utilizado el
algoritmo SVM, seleccionando 320 características, con la siguiente
configuración:

\begin{itemize}
    \item Parámetro de regularización (C): 0.5
    \item Función <<kernel>>: polinomial
    \item Grado de la función <<kernel>>: 5
    \item Tolerancia para el criterio de parada: 0.001
\end{itemize}

Este modelo tiene una precisión media del 78,85\%. Se debe tener en cuenta que
este valor se ha medido realizando validación cruzada con 5 repeticiones con 2
<<folds>>, por lo que esta precisión es la obtenida entrenando modelos
únicamente con el 50\% de los datos disponibles, entonces es de esperar que el
rendimiento del modelo final, entrenado con todos los datos, sea algo mayor.

Para mostrar estos resultados se ha usado la métrica de precisión, aunque se
está trabajando con un conjunto de datos ligeramente desbalanceado. Se ha
comprobado que la diferencia entre el número de instancias de cada clase no es
lo suficientemente grande como para que exista un cambio significativo entre la
precisión y, por ejemplo, el valor F1. Se ha decidido utilizar la precisión ya
que es un valor mucho más intuitivo y fácil de visualizar.

\section{Fase de desarrollo de la aplicación}

Se ha creado una aplicación web que permite interactuar con un modelo de
aprendizaje automático de forma simple. Debido a las características del
programa una aplicación móvil podría ser una buena alternativa para facilitar la
toma del vídeo. Por esto se quiso facilitar en la medida de lo posible la
extensión futura del sistema con cambios mínimos de funcionalidad preexistente.

Para cumplir con lo anterior se decidió crear una API (Aplication Programming
Interface) REST en la que se implemente toda la funcionalidad de la aplicación
junto con una página web que sirva como <<frontend>> que se comunique con la API
mediante peticiones HTTP. Este enfoque deja la puerta abierta a futuras
extensiones (como una aplicación móvil) sobre el sistema sin la necesidad de
realizar cambios sobre el código ya existente. Estas extensiones podrían ser
realizadas por cualquier persona, incluso si no está involucrada directamente en
este proyecto.

\subsection{Docker}

Para facilitar la creación del entorno de desarrollo y el despliegue de la
aplicación se ha empleado la popular herramienta Docker. Esto permite la
creación de <<contenedores>> de forma determinista, es decir, obteniendo siempre
un sistema idéntico, solucionando el típico problema de <<funciona en mi
máquina>>.

Para esta aplicación se emplean cuatro contenedores:

\begin{itemize}
    \item API (Basado en \href{https://fastapi.tiangolo.com/}{FastAPI})
    \item Aplicación web (Basado en \href{https://nodejs.org/en}{NodeJS})
    \item Proxy inverso (Basado en \href{https://caddyserver.com/}{Caddy})
    \item Base de datos (Basado en \href{https://www.postgresql.org/}{PostgreSQL})
\end{itemize}

\subsection{Proxy inverso}

Un proxy inverso permite redireccionar peticiones de forma dinámica al destino
adecuado. Esto es generalmente usado en lo que se conoce como balance de carga
(\textit{load balancing}).

Como tanto la API como la aplicación web están alojadas en la misma máquina se
necesita alguna forma para diferenciar qué peticiones van a qué servicio. Siendo
\textit{dominio} el dominio principal de la aplicación, se ha decidido que
\textit{dominio} vaya a la aplicación web y qué \textit{api.dominio} vaya a la
api, en este caso \textit{dominio} es
\href{https://paddel.catalin.sh}{paddel.catalin.sh}. Configuraciones como esta
se deben realizar en el archivo \texttt{.env} en la raíz del proyecto de docker
(directorio \texttt{/app} del repositorio).

Para lograr lo anterior se deben añadir registros DNS desde el panel de
administración del servidor de nombres de dominio elegido (CloudFlare en este
caso) para hacer que \textit{dominio} y \textit{api.dominio} apunten a la
dirección ip del equipo en el que se aloja la aplicación. Con esto se consigue
que las peticiones realizadas a los dominios lleguen a la máquina en cuestión.

A continuación, se debe redirigir la petición dentro de la máquina al contenedor
respectivo. Para esto se utiliza el servidor web Caddy, que permite la creación
de un proxy inverso con el que se pueden redirigir peticiones en función del
dominio al que estén dirigidas.

Además, Caddy permite la obtención y renovación automática de certificados SSL
de una entidad certificadora (en concreto \href{https://letsencrypt.org/}{Let's
Encrypt}) cuyos certificados se consideran de confianza en la mayoría de
navegadores.

\subsection{Make}

GNU Make es una herramienta usada para coordinar la ejecución de secuencias de
comandos. Es muy usada en el proceso de compilación de programas escritos en C o
C++ debido a lo complejos que pueden llegar a ser los comandos necesarios.

En este caso GNU Make ha sido usado para simplificar la ejecución de comandos
comunes. Algunas acciones que se realizan son:

\begin{itemize}
    \item Lanzar los contenedores de Docker para el desarrollo.
    \item Lanzar los contenedores de Docker para producción.
    \item Buscar posibles errores de tipado en código Python.
    \item Formatear el código Python.
    \item Compilar los archivos \LaTeX{} para generar esta documentación.
    \item \dots
\end{itemize}

\subsection{Accesibilidad}

El público objetivo de esta aplicación son aquellas personas que padezcan o
puedan padecer la enfermedad de Parkinson. Los problemas de movilidad causados
por esta enfermedad reducen la precisión con la que se puede usar una
herramienta como un ratón y se deben utilizar métodos alternativos para los que
se debe implementar soporte explícitamente en el código de una página web.

Para asegurar el uso correcto de las diferentes herramientas de accesibilidad
que los navegadores implementan se ha realizado el
\href{https://www.udacity.com/course/web-accessibility--ud891}{curso sobre
accesibilidad web de Udacity}, que se puede ver de forma gratuíta en
\href{https://www.youtube.com/playlist?list=PLcJAkgdenpsci0IJziU4bCk3dTQLpJU7R}{esta
lista de reproducción de YouTube}.

El concepto más importante adquirido es lo que se conoce como <<accessibility
tree>>, que es una estructura de árbol que se genera automáticamente a partir
del código HTML de una página web. En esta estructura se eliminan todos los
elementos visuales, y quedan solo aquellos elementos con contenido (encabezados,
párrafos, etc.) o funcionalidad (botones, links, etc.).

Cuando se utiliza una página web únicamente con el teclado (utilizando las
teclas de tabulación y flechas) se está navegando a través de los elementos
funcionales del árbol de accesibilidad.

Otros conceptos sobre accesibilidad de gran importancia son:

\begin{itemize}
    \item Existen atributos ARIA (Accessible Rich Internet Applications) que
    deben ser utilizados para especificar aspectos relacionados con la
    accesibilidad como, por ejemplo, el orden de tabulado de los elementos.
    \item Es importante utilizar elementos HTML preexistentes cuando sea
    posible. Por ejemplo, utilizar el elemento \texttt{dialog} para crear
    ventanas <<pop-up>> o emergentes en lugar de \texttt{div}, que es un
    contenedor genérico. Estos elementos más específicos añaden información
    semántica sobre el propósito y el uso de un componente, además de
    funcionalidad común adicional, por ejemplo, un elemento \texttt{dialog} se
    cierra automáticamente al pulsar la tecla \texttt{Esc} sin necesidad de
    añadir código JavaScript propio.
    \item Existen patrones y métodos estándar para implementar componentes y
    funcionalidades comunes en la web, como menús desplegables, listas, etc.
    Estos se pueden encontrar en la
    \href{https://www.w3.org/WAI/ARIA/apg/patterns/}{Guía de prácticas de
    autoría de ARIA}, mantenida por el W3C (World Wide Web Consortium). Estas
    recomendaciones homogeneizan la forma de uso de elementos comunes, lo que es
    especialmente importante para personas con accesibilidad limitada.
    \item Las personas con visión reducida dependen de un lector de pantalla
    para saber el contenido al que están accediendo. Esto se debe tener en
    cuenta para utilizar los atributos ARIA adecuados, por ejemplo:
        \begin{itemize}
            \item Para comunicar sobre el estado de una barra de progreso se
            emplean los atributos \texttt{aria-valuenow}, \texttt{aria-valuemin}
            y \texttt{aria-valuemax}.
            \item Para anunciar al usuario de un mensaje si, por ejemplo, le
            llega un correo mientras navega por su bandeja de entrada, se emplea
            el atributo \texttt{aria-live}. Que puede tomar los valores
            \texttt{assertive}, \texttt{off} y \texttt{polite}, dependiendo del
            tipo de interrupción que se desee realizar.
        \end{itemize}
\end{itemize}

Estos conocimientos han sido utilizados a través de la aplicación y, aunque no
ha sido probada por una persona con accesibilidad reducida, se ha intentado
navegar la página únicamente con un lector de pantalla para buscar posibles
errores y mejoras.

\subsection{Autentificación}

Para acceder al panel de gestión de modelos y usuarios es necesario realizar una
verificación de identidad. Para esto se utiliza un simple nombre de usuario y
contraseña. Cuando se introducen los datos estos son enviados a la API, donde se
comparan con la base de datos\footnote{Las contraseñas se almacenan cifradas con
<<salt>> mediante la función de hasheado <<bcrypt>>.}, si no se puede verificar
la identidad se responde con un error.

Si la verificación es exitosa se devuelve un JWT (JSON Web Token), que es una
cadena de caracteres cuyo contenido puede ser descifrado por cualquier persona.
La característica importante de estos JWT es que son firmados mediante una
cadena secreta que se almacena en el servidor. Cualquier persona en posesión de
esta cadena puede generar sus propios JWT, que se considerarán veraces por la
aplicación.

Este token JWT se guarda en la memoria local (local storage) del navegador
correspondiente al dominio de la web y se envía junto a todas las peticiones
posteriores que se hacen a la API. Al contrario que las <<cookies>>, las
variables almacenadas en memoria local no son enviadas automáticamente por el
navegador con cada petición, sino que deben ser utilizadas explícitamente por el
código JavaScript, esto elimina la posibilidad del ataque conocido como CSRF
(Cross Site Request Forgery), que depende del uso de <<cookies>> como token de
autentificación.

Otra ventaja del uso de JWT es que se pueden utilizar de tal forma que no sea
necesario almacenar información sobre la sesión de los usuarios en el servidor.
Como parte de la información firmada que contiene el JWT se puede incluir la
fecha de expiración de este, esto se procesa en el servidor para determinar su
estado de validez.

Una gran desventaja de este método de autentificación es que, si el navegador
del usuario se viese comprometido, el JWT podría ser utilizado para suplantar su
identidad ante la aplicación sin la posibilidad de deshabilitar dicho token de
forma sencilla. Pese a esto se ha optado por este método debido a su simplicidad.
