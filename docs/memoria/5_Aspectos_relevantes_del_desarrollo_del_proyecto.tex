\capitulo{Aspectos relevantes del desarrollo del proyecto}
\label{cha:Aspectos relevantes del desarrollo del proyecto}

Este apartado contiene algunos aspectos relevantes sobre el desarrollo del
proyecto, incluyendo las razones detrás de las decisiones tomadas durante este y
el impacto que dichas decisiones han tenido sobre los resultados obtenidos.

\section{Fase de experimentación}

El conjunto de datos disponible durante la fase de experimentación consisten en
158 muestras con los siguientes <<atributos>>:

\begin{itemize}
    \item Si la persona correspondiente a la instancia padece la enfermedad de
    Parkinson. Es lo que se busca predecir.
    \item Archivo de vídeo de una mano de la persona realizando la prueba de
    <<finger-tapping>>.
    \item Mano que aparece en el vídeo (izquierda o derecha).
    \item Fecha en la que se ha tomado el vídeo (irrelevante).
    \item Edad de la persona.
    \item Sexo de la persona.
    \item Mano dominante de la persona.
\end{itemize}

Cabe destacar que se ha tomado una muestra de cada mano de cada persona. Por lo
que este conjunto de datos ha sido obtenido de 79 personas. Aún así, se ha
tomado cada mano como una instancia distinta con el objetivo de tener más
instancias con las que trabajar.

Además, se dispone de 69 instancias de personas que padecen la enfermedad de
Parkinson y 89 instancias de personas sanas, por lo que se está trabajando con
un conjunto de datos ligeramente desbalanceado. Esto deberá tenerse en cuenta
para que no influya en los resultados obtenidos, por ejemplo, seleccionando
métricas adecuadas.

\subsection{Procesado de vídeo}

El objetivo de la fase de experimentación es crear un sistema que tenga como
entrada los atributos antes mencionados (salvo el objetivo) y por salida si esos
atributos corresponden con una persona que padece la enfermedad de Parkinson
(posiblemente junto con el grado de confianza de la predicción).

Los algoritmos de aprendizaje automático típicamente están diseñados para
trabajar con atributos numéricos, por lo que los atributos disponibles deben ser
transformados durante el preprocesado. Esto se puede realizar en la mayoría de
casos mediante simples métodos de minería de datos, como, por ejemplo, la
codificación de variables categóricas. Pero hay un problema, el archivo de
vídeo.

En este caso, una imagen es una matriz bidimensional donde cada celda contiene
una 3-tupla representando los valores rojo, verde y azul del pixel con el que se
corresponde. Un vídeo es una secuencia de imágenes junto con información
adicional, es este caso sólamente es relevante la tasa de refresco, que es la
frecuencia a la que ha sido capturada cada imagen. Esto es de gran importancia
para dar una componente temporal al vídeo.

Con lo anterior se puede ver que un vídeo no se puede utilizar de forma directa,
sino que deberá pasar por una fase multietapa de preprocesado para ser
transformado a un conjunto de valores numéricos que lo describen.

\subsubsection{Extracción de <<landmarks>>}

Una <<landmark>> en el campo de la visión aritificial es un punto de referencia
que se corresponde con un objeto físico. El objetivo de esta fase es convertir
el vídeo de la prueba de <<finger-tapping>> a una secuencia o serie temporal de
conjuntos de <<landmarks>> los cuales representan la posición de la mano durante
un instante concreto.

El primer paso para lograr esto es leer las imágenes del archivo de vídeo, esto
ha sido logrado mediante la librería de <<bindings>> de OpenCV para Python.
OpenCV es una librería de uso general para realizar tareas relacionadas con la
visión artificial, y permite leer multitud de formatos de vídeo mediante un
flujo de imágenes.

Se ha tomado especial precaución para no cargar en memoria todas las imágenes
del vídeo, sino ir leyéndolas cuando son necesarias. Un archivo de vídeo ocupa
relativamente poco espacio en disco debido a que está codificado mediante un
<<codec>> determinado, lo que reduce el tamaño del archivo. Pero, para poder
trabajar con las imágenes del vídeo, este debe ser decodificado.

La magnitud de lo anterior se ve claramente con el siguiente ejemplo. Un vídeo
con una resolución de 1920x1080 a 30 fotogramas por segundo codificado mediante
el codec H264 que ocupa 50,7MB, decodificado, ocuparía en torno a los 3,7GB.

A continuación se deben extraer las <<landmarks>> de las imágenes leidas. Esto
ha sido logrado mediante la librería Mediapipe Hands \cite{zhang2020mediapipe},
que permite extraer los siguentes puntos a partir de una imágen:

\imagen{relevant_aspects/hand-landmarks.png}{Mediapipe Hands <<Landmarks>>}{1}

Debido a la perspectiva desde la que se han tomados los vídeos de la prueba de
<<finger-tapping>> hay algunas <<landmarks>> que quedan ocultas en varias
ocasiones, lo que hace su posición detectada poco fiable. Por lo que se desechan
las <<landmarks>> en el intervalo [9-17] para solo tomar en cuenta la parte
<<frontal>> de la mano.

Mediapipe Hands ofrece la posibilidad de extraer <<landmarks>> de las imágenes
como si estas no tuviesen relación entre sí o realizar la extracción teniendo en
cuenta que se trata de un vídeo, así teniendo en cuenta resultados anteriores
para determinar de forma más precisa las <<landmarks>> del fotograma actual.
Esto tiene la gran desventaja de que hace imposible la paralelización de este
proceso (debido a que cada extracción depende de los resultados anteriores).

Lo anterior no tiene un gran efecto durante la fase de investigación, ya que sí
se puede paralelizar la extracción de <<landmarks>> de cada vídeo. Donde sí
tiene efecto es sobre la aplicación web, empeorando la experiencia de los
usuarios.

En última instancia se tomó la decisión de no usar paralelización, y así obtener
resultados más precisos. Una alternativa planteada fue realizar la extracción en
paralelo solamente en la aplicación, pero esto se descartó ya que esto podría
introducir inconsistencias y variables adicionales que deberían ser tomadas en
cuenta.

\subsubsection{Extracción de series temporales}

Tras el proceso descrito en el apartado anterior se dispone una secuencia de
datos similar a la siguiente:

\imagen{relevant_aspects/poses_series.png}{Serie temporal de <<landmarks>>}{1}

Cada fila representa la pose de la mano durante un fotograma concreto. Se puede
observar que el índice es una fecha completa en lugar de otras opciones más
convenientes como los segundos desde el inicio del vídeo o lo que se conoce como
<<timestamp>>. Esto es una imposición de TSFresh para poder realizar la
extracción de características teniendo en cuenta esta componente temporal.

Cada celda representa el punto en el espacio en el que se encuentra la
<<landmark>> correspondiente en un instante de tiempo.

Aunque estas series temporales son una simplificación muy grande de lo vídeos
iniciales, aún no son del todo útiles. Al ser información sobre la posición en
el espacio, es dependiente de la forma en la que ha sido tomada la grabación. En
un entorno controlado esto no sería mucho problema, pero en este caso, como se
desea hacer el uso del sistema accesible a cualquier persona sin necesitar
equipamiento especial, se deben buscar alternativas.

En este caso se ha decidido tomar el ángulo entre el ángulo entre la punta del
dedo pulgar, la muñeca y la punta del dedo índice. Esta medida es útil ya que no
depende de cómo se ha tomado el vídeo ni del tamaño de la mano de la persona.
Quedando como resultado una serie temporal como la siguiente:

\imagen{relevant_aspects/angle_series.png}{Serie temporal de ángulos}{0.5}

La unidad usada en estos ángulos es el radián.

\subsubsection{Extracción de características}

El último paso para convertir un archivo de vídeo a atributos útiles para
entrenar un modelo de aprendizaje es extraer características que describan la
serie temporal obtenida. Algunos de estos atributos han sido extraídos de forma
específica teniendo en cuenta este problema concreto, mientras que otros (la
mayoría) son atributos genéricos de series temporales.

\paragraph{Detección de toques y amplitudes}

Para varios atributos específicos al problema han sido utilizados los instantes
de tiempo en los que se producen toques (el pulgar y el índice tocan) y
amplitudes máximas en el movimiento de <<finger-tapping>>.

La detección de estos instantes ha sido realizada mediante una búsqueda de
máximos gracias a la función \texttt{find\_peaks} de la librería
\href{https://scipy.org/}{scipy}. Pero esta función por si sola no da muy buenos
resultados.

\imagen{relevant_aspects/raw_peaks.png}{Amplitudes}{0.7}

El eje horizontal representa el tiempo que ha transcurrido desde el inicio del
vídeo. El eje vertical representa el ángulo en radianes entre el dedo índice, la
muñeca y el pulgar.

Se puede apreciar que obtener todos los máximos locales no es la mejor opción,
debe incorporarse algún criterio para determinar si un máximo debería tenerse en
cuenta o no. La función \texttt{find\_peaks} tiene algunos parámetros para este
propósito.

Tras probar varias opciones y comprobar manualmente los resultados obtenidos
sobre diferentes vídeos, se determinó que la mejor opción es establecer la
prominencia mínima (parámetro \texttt{prominence} de \texttt{find\_peaks}) que debe tener
un máximo local para ser considerado.

La prominencia se define como la medida que determina cuánto destaca un máximo
con respecto a sus máximos más cercanos. Se probaron varios valores estáticos,
pero como cada vídeo tiene características diferentes era necesario utilizar
algo más dinámico. La desviación típica se comportaba bastante bien, pero cuando
la amplitud variaba con el tiempo (síntoma de la enfermedad de Parkinson) los
máximos de menor magnitud no eran detectados.

Lo anterior fue solucionado  mediante el uso de una desviación típica móvil. Se
establece una ventana que determina la <<zona>> a la que pertenece un valor y se
utiliza la desviación típica de esa <<zona>> como prominencia mínima para que el
punto pueda ser considerado un máximo.

\imagen{relevant_aspects/rolling_std_peaks.png}{Amplitudes mediante desviación típica móvil}{0.7}

Se puede apreciar que los resultados son ampliamente mejores. Incluso cuando la
amplitud decrece con el tiempo:

\imagen{relevant_aspects/rolling_std_peaks_id.png}{Amplitudes mediante desviación típica móvil con la enfermedad de Parkinson}{0.7}

Aunque si el movimiento es errático, los resultados también lo son, como es de
esperar.

\imagen{relevant_aspects/rolling_std_peaks_erratic.png}{Amplitudes mediante desviación típica móvil con movimiento errático}{0.7}

Para detectar los toques (mínimos) es tan simple como utilizar la serie de
ángulos negada para detectar los puntos donde se encuentran los máximos. Además
se ha establecido un umbral para que solo se consideren toques si se encuentra
entre 0 y 0,1 radianes.

\imagen{relevant_aspects/rolling_std_valleys.png}{Amplitudes mediante desviación típica móvil con movimiento errático}{0.7}

\paragraph{Características detectadas}

A continuación se van a detallar algunas de las características extraídas de
mayor interés. Estos valores ya son atributos que describen el vídeo, por lo que
pueden ser utilizados para la generación de un modelo.

\begin{itemize}
    \item \textbf{Velocidad media del movimiento}: Una característica de la
    bradicinesia es la ralentización del movimiento. Esto va a ser reflejado en
    la velocidad media (en radianes por segundo) que tiene el movimiento
    \item \textbf{Frecuencia de amplitudes y toques}: Dos magnitudes que miden
    cuantos toques o amplitudes se realizan por segundo de media durante el
    movimineto.
    \item \textbf{Amplitud media}: Otra característica de la enfermedad de
    Párkinson es la debilidad, lo que se puede ver reflejado sobre la amplitud
    media del movimiento. Es simplemente la media de las amplitudes antes
    detectadas.
\end{itemize}

Además de las anteriores, se extrayeron 794 características genéricas
mediante la librería TSFresh.

\subsection{Limpieza de datos}

En este punto se dispone de un conjunto de 158 instancias y unos 800 atributos,
algunos de ellos categóricos, estos deberán ser codificados para que sean
atributos numéricos, con los que se trabaja mejor.

Además, se determinó que todas las instancias deberán tener un tiempo de
detección de la mano realizando la prueba de <<finger-tapping>> mínimo de 15
segundos para garantizar en cierto modo la precisión de los atributos extraidos
y poder compara instancias con el mínimo número de influencias sobre las que no
se tiene control.

Debido a la decisión anterior se pasó de disponer de 158 instancias a únicamente
156. Esto es desafortunado debido al ya pequeño número de muestras, pero se
consideró una pérdida que merece la pena con el fin de obtener mejores
resultados.

Por último se sustituyeron las característica <<mano dominante>> y <<mano que
aparece en el vídeo>> por una única característica <<es la mano que aparece en
el vídeo la dominante>> con el objetivo de reducir la conocida <<maldición de la
dimensionalidad>> al mismo tiempo que se mantiene la información relevante.

\subsection{Normalización}

Algunos algoritmos se ven muy afectados por la escala en la que se presentan los
atributos, uno de los casos más claros es <<\textit{k} vecinos más cercanos>>.

Debido a esto es importante normalizar los atributos. Se han probado varios
métodos y encontrado que la normalización por cuantiles funciona ligeramente
mejor que sus contrapartidas.

La normalización por cuantiles se caracteriza por hacer que los estadísticos de
cada atributo sean idénticos a los de una distribución concreta (en este caso
una distribución uniforme). Esto se consigue ignorando la magnitud de un
atributo y teniendo en cuenta únicamente su posición en la secuencia de todas
las instancias ordenadas según el atributo que se está normalizando.

Al no tener en cuenta la magnitud, la transformación anterior es de gran
utilidad para tratar lo que se conoce como <<outliers>>, que son instancias con
atributos que se alejan mucho de la regla.

\subsection{Búsqueda del mejor modelo}

En este punto se dispone de 4 conjuntos de datos sobre 156 instancias:

\begin{itemize}
    \item \textbf{Atributos iniciales}: Atributos de los que se disponía al
    inicio, como la edad o el sexo de la persona.
    \item \textbf{Atributos extraídos de vídeo propios}: Son los atributos cuya
    extracción ha sido descrita en los apartados anteriores, como la velocidad
    del movimiento o la frecuencia de toques.
    \item \textbf{Atributos extraídos de vídeo con TSFresh}: Son los 794
    atributos del vídeo extraídos mediante TSFresh.
    \item \textbf{Variable objetivo}: Si la instancia corresponde con una
    persona que padece la enfermedad de Parkinson. Es lo que se intenta predecir.
\end{itemize}

A priori es muy difícil o incluso imposible saber cómo van a comportarse
diferentes algoritmos al enfrentarse a distintos subconjuntos de la información
diponible. Por lo que la única opción es probar diferentes configuraciones con
la esperanza de encontrar una que se adapte considerablemente bien a los datos.
En este sentido el aprendizaje automático es más un arte que una ciencia exacta.

En este caso se ha realizado una búsqueda exhaustiva (o \textit{grid-search})
con las siguientes variables:

\begin{itemize}
    \item \textbf{Conjunto de datos}: El conjunto de datos utilizado para el
    entrenamiento ha sido cambiado de dos formas distintas:
    \begin{itemize}
        \item Distintas combinaciones del los conjuntos de datos anteriores.
        \item Selección de un distinto número de los atributos según su
        relevancia estimada mediante TSFresh.
    \end{itemize}
    \item \textbf{Algoritmo de aprendizaje}: Se han probado varios algoritmos de
    aprendizaje. (Máquinas de vectores de soporte, Naive Bayes, \textit{k}
    vecinos más cercanos, Perceptrón multicapa, AdaBoost, etc.)
    \item \textbf{Parámetros de los algoritmos}: Se ha variado la configuración
    de cada uno de los algoritmos anteriores. Este proceso se denomina
    optimización de hiperparámetros.
    
    Además, existen combinaciones de parámetros sin sentido, por ejemplo, variar
    el grado de la función para una máquina de vectores de soporte con
    <<kernel>> lineal. Esto se debe tener en cuenta para no aumentar el tiempo
    requerido de foma inútil.
\end{itemize}

Cabe destacar que la selección de características se realiza teniendo en cuenta
la totalidad del conjunto de datos, no solo el de entrenamiento. Esto produce
fugas de información durante la validación cruzada ya que las características
seleccionadas son la consideradas mejores tanto para el conjunto de
entrenemiento como el de test.

Una opción para solventar lo anterior es realizar la selección de
características en cada <<fold>> de la validación cruzada, usando únicamente el
conjunto de entrenamiento. Pero esta operación es muy costosa al trabajar con
cientos de atributos. Este cambio incrementa la duración de la búsqueda
<<grid-search>> en varios órdenes de magnitud. Se tomó la decisión de aceptar
las fugas de información ya que lo que se pretende es comparar el rendimiento de
distintos modelos, por lo que los resultados van a seguir siendo relevantes.

\subsubsection{Resultados}

Tras realizar la búsqueda se ha obtenido una tabla de dimensiones bastante
granded (con una fila por cada combinación de variables probada) con los
resultados obtenidos.

En este apartado se exponen los resultados obtenidos además de algunos detalles
interesantes.



\section{Fase de desarrollo de la aplicación}

Se ha creado una aplicación web que permite interactuar con un modelo de
aprendizaje automático de forma simple. Debido a las características del
programa una aplicación móvil podría ser una buena alternativa para facilitar la
toma del vídeo. Por esto se quiso facilitar en la medida de lo posible la
extensión futura del sistema con cambios mínimos de funcionalidad preexistente.

Para cumplir con lo anterior se decidió crear una API (Aplication Programming
Interface) REST en la que se implemente toda la funcionalidad de la aplicación
junto con un una página web que sirva como <<frontend>> que se comunique con la
API mediante peticiones HTTP. Este enfoque deja la puerta abierta a futuras
extensiones (como una aplicación móvil) sobre el sistema sin la necesidad de
realizar cambios sobre el código ya existente. Estas extensiones podrían ser
realizadas por cualquier persona, incluso si no ha estado involucrada en este
proyecto con antelación.

\subsection{Docker}

Para facilitar la creación del entorno de desarrollo y el despliegue de la
aplicación se ha empleado la popular herramienta Docker. Esto permite la
creación de <<contenedores>> de forma determinista, es decir, obteniendo siempre
un sistema idéntico, solucionando el típico problema de <<funciona en mi
máquina>>.

Para esta aplicación se emplean cuatro contenedores:

\begin{itemize}
    \item API (Basado en \href{https://fastapi.tiangolo.com/}{FastAPI})
    \item Aplicación web (Basado en \href{https://kit.svelte.dev/}{SvelteKit})
    \item Proxy inverso (Basado en \href{https://caddyserver.com/}{Caddy})
    \item Base de datos (Basado en \href{https://www.postgresql.org/}{PostgreSQL})
\end{itemize}

\subsection{Proxy inverso}

Un proxy inverso permite redireccionar peticiones de forma dinámica al destino
adecuado. Esto es generalmente usado en lo que se conoce como balance de carga
(\textit{load balancing}).

Como tanto la API como la aplicación web están alojadas en la misma máquina se
necesita alguna forma para diferenciar qué peticiones van a qué servicio. Se ha
decidido que \textit{dominio} vaya a la aplicación web y que
\textit{api.dominio} vaya a la api, en este caso \textit{dominio} es
\href{https://paddel.catalin.sh}{paddel.catalin.sh}. Configuraciones como esta
se deben realizar en el archivo \texttt{.env} en la raíz del proyecto de docker
(directorio \texttt{/app} del repositorio).

Para lograr lo anterior se deben añadir registros DNS desde el panel de
administración del servidor de nombres de dominio elegido (CloudFlare en este
caso) para hacer que \textit{dominio} y \textit{api.dominio} apunten a la
dirección ip del equipo en el que se aloja la aplicación. Con esto se consigue
que las peticiones realizadas a los dominios vayan lleguen a la máquina en
cuestión.

A continuación se debe redirigir la petición dentro de la máquina al contenedor
respectivo. Para esto se utiliza el servidor web Caddy, que permite la creación
de un proxy inverso con el que se pueden redirigir peticiones en función del
dominio al que vayan dirigidas.

Además, Caddy permite la obtención y renovación automática de certificados SSL
de una entidad certificadora (en concreto \href{https://letsencrypt.org/}{Let's
Encrypt}) cuyos certificados son de confianza en la mayoría de navegadores.

\subsection{Make}

GNU Make es una herramienta usada para coordinar la ejecución de secuencias de
comandos. Es muy usada en el proceso de compilación de programas escritos en C o
C++ debido a lo complejos que pueden llegar a ser los comandos necesarios.

En este caso GNU Make ha sido usado para simplificar la ejecución de comandos
comunes. Algunas acciones que se realizan son:

\begin{itemize}
    \item Lanzar los contenedores de Docker para el desarrollo.
    \item Lanzar los contenedores de Docker para producción.
    \item Buscar posibles errores de tipado en código Python.
    \item Formatear el código Python.
    \item Compilar los archivos \LaTeX{} para generar esta documentación.
    \item \dots
\end{itemize}
